{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Linear Regression with Pytorch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple Linear Regression Model with sklearn"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. load data\n",
    "cols = [\"CRIM\",\n",
    "    \"ZN\",\n",
    "    \"INDUS\",\n",
    "    \"CHAS\",\n",
    "    \"NOX\",\n",
    "    \"RM\",\n",
    "    \"AGE\",\n",
    "    \"DIS\",\n",
    "    \"RAD\",\n",
    "    \"TAX\",\n",
    "    \"PTRATIO\",\n",
    "    \"B\",\n",
    "    \"LSTAT\",\n",
    "    \"MEDV\",\n",
    "]\n",
    "# https://raw.githubusercontent.com/rasbt/python-machine-learning-book/master/code/datasets/housing/housing.data\n",
    "df = pd.read_csv(\n",
    "    \"../data/raw/housing.data.txt\",\n",
    "    delimiter=r\"\\s+\",\n",
    "    names=cols,\n",
    ")\n",
    "df = df.dropna()\n",
    "X = df.drop(\"MEDV\", axis=1)\n",
    "y = df[[\"MEDV\"]]\n",
    "\n",
    "# 2. Split Train and Test Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=5\n",
    ")\n",
    "\n",
    "# 3. Fit model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# 4. Measure performane\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE: 20.86929218377065\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Components\n",
    "### 1. Prediction\n",
    "### 2. Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction\n",
    "## Mathematical formula\n",
    "$$\n",
    "\\begin{align}\n",
    "y=w^Tx+b\n",
    "\\end{align}\n",
    "$$\n",
    "- notations\n",
    "    - **w**: weight vector(D x 1 dim.)\n",
    "    - **x**: input vector(D x 1 dim.)\n",
    "    - b: intercept\n",
    "    - D: the number of features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import numpy as np\n",
    "D = 10\n",
    "w = np.ones((D, 1))\n",
    "x = np.ones((D, 1))\n",
    "b = 0\n",
    "\n",
    "# using for loop\n",
    "prediction = 0\n",
    "for i in range(D):\n",
    "    prediction += w[i][0]*x[i][0]\n",
    "    prediction = prediction+b\n",
    "\n",
    "\n",
    "# vectorized\n",
    "prediction = w.T.dot(x)+b"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training\n",
    "## Cost function(= Loss function)\n",
    "### Cost function of linear regression: Mean Squared Error\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "J = \\frac{1}{N}\\sum_{i=1}^N(H(x^{(i)})-y^{(i)})^2\n",
    "\\end{align}\n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "J = \\frac{1}{N}\\sum_{i=1}^N((w*x^{(i)}+b)-y^{(i)})^2\n",
    "\\end{align}\n",
    "$$\n",
    " - MAE를 최소가 되게 하는 **w**를 찾는다!\n",
    "\n",
    "\n",
    "## Optimization Method\n",
    "- 위에 정의한 cost function을 최대화 하기위해서는 어떠한 과정이 필요한가?\n",
    "- 선형회귀의 경우, 미분을 사용해서 해를 구할 수 있음!\n",
    "- 단, 일반적으로는 수리적인 방법(Ex. 동전던지기의 확률을 구한 방법, 미분 등)으로 해를 구할 수 없음\n",
    "- Optimization Method의 대표적인 예: **Gradient descent**\n",
    "    - Mathematical Formula\n",
    "$$\n",
    "\\begin{align}\n",
    "w \\leftarrow w - \\eta{\\nabla}_wJ\n",
    "\\end{align}\n",
    "$$\n",
    "$$\n",
    "\\begin{align}\n",
    "{\\nabla}_nJ=\\sum_{n=1}^Nx^{(i)}(H(x^{(i)})-y^{(i)})\n",
    "\\end{align}\n",
    "$$\n",
    "<img src=\"../figures/GradientDescentGIF.gif\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "--------------------\n",
    "\n",
    "## 조금 더 깊게\n",
    "\n",
    "- 기계학습의 “학습”은 단순히 모델의 가중치(w)를 찾아내는 것\n",
    "    - 비유하자면, 새로운 기억이 생성될 때마다, 뇌에 있는 각 시냅스 간의 연결의 세기가 변한다!\n",
    "- 이러한 관점에서, 기계학습 문제는 단순히 주어진 데이터(X, y)를 가장 잘 설명하는 가중치를 찾아내는 것이다.\n",
    "- 이러한 가중치를 찾아내는 방법 중 가장 많이 사용되는 것이 최대우도추정(Maximum likelihood Estimation) 방법이다. \n",
    "\n",
    "### Base theorem\n",
    "![basetherom](../figures/baise_theorem.png)\n",
    "\n",
    "### Likelihood?\n",
    "<!-- ![likelihoood](../figures/likelihood2.png) -->\n",
    "<img src=\"../figures/likelihood2.png\" alt=\"drawing\" width=\"600\"/>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for i in range()\n",
    "\n",
    "# gradient_w = X.T.dot(Y-T)\n",
    "\n",
    "# # 실제 학습 시에는, 업데이트 횟수를 정하거나, loss(cost)의 값의 제한을 둔 후 loop를 돌림\n",
    "# for epoch in range(num_epochs):\n",
    "#     w = w - learning_rate*X.T.dot(Y-T)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# References\n",
    "likelihood1: https://jjangjjong.tistory.com/41  \n",
    "likelihood2: https://angeloyeo.github.io/2020/07/17/MLE.html  \n",
    "cost function: https://computer-nerd.tistory.com/5  \n",
    "Deriving Machine Learning Cost Functions using Maximum Likelihood Estimation: https://allenkunle.me/deriving-ml-cost-functions-part1  \n",
    "Linear Regression Normality: https://stats.stackexchange.com/questions/327427/how-is-y-normally-distributed-in-linear-regression  \n",
    "gradient descent: https://mccormickml.com/2014/03/04/gradient-descent-derivation/  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "250c32ece4d06cfbaa606ac1fa53dfb2f6f512101e7381009ea9545415be61b5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}